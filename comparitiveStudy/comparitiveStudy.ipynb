{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset\n",
    "\n",
    "Manual inspections of monojet_Zp2000.0_DM_50.0_chan3.csv indicates a row can have at max 65 columns.\n",
    "This means an event can contain an event in monojet_Zp2000.0_DM_50.0_chan3.csv can contain at max 10 objects.\n",
    "To accomodate for the additional ';' delimiter at the end of line, we consider an additional column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_columns = 65\n",
    "column_names = ['event ID', 'process ID', 'event weight', 'MET', 'METphi']\n",
    "n_obj = int((max_columns - 5) / 5) \n",
    "for i in range(1, n_obj + 1): #Subtracting 5 because first few columns are meta-data.\n",
    "    column_names.extend([f'obj{i}', f'E{i}', f'pt{i}', f'eta{i}', f'phi{i}'])\n",
    "    \n",
    "column_names.append('sentinel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../monojet_Zp2000.0_DM_50.0_chan3.csv', header=None, sep=',|;', \n",
    "                 names=column_names, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event ID</th>\n",
       "      <th>process ID</th>\n",
       "      <th>event weight</th>\n",
       "      <th>MET</th>\n",
       "      <th>METphi</th>\n",
       "      <th>obj1</th>\n",
       "      <th>E1</th>\n",
       "      <th>pt1</th>\n",
       "      <th>eta1</th>\n",
       "      <th>phi1</th>\n",
       "      <th>...</th>\n",
       "      <th>obj11</th>\n",
       "      <th>E11</th>\n",
       "      <th>pt11</th>\n",
       "      <th>eta11</th>\n",
       "      <th>phi11</th>\n",
       "      <th>obj12</th>\n",
       "      <th>E12</th>\n",
       "      <th>pt12</th>\n",
       "      <th>eta12</th>\n",
       "      <th>phi12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354</td>\n",
       "      <td>monojet_Zp2000.0_DM_50.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>832841.0</td>\n",
       "      <td>-1.22431</td>\n",
       "      <td>b</td>\n",
       "      <td>947383.0</td>\n",
       "      <td>824498.0</td>\n",
       "      <td>-0.523103</td>\n",
       "      <td>1.644210</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354</td>\n",
       "      <td>monojet_Zp2000.0_DM_50.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>732115.0</td>\n",
       "      <td>1.17245</td>\n",
       "      <td>j</td>\n",
       "      <td>1069460.0</td>\n",
       "      <td>751597.0</td>\n",
       "      <td>0.858186</td>\n",
       "      <td>-1.842170</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>monojet_Zp2000.0_DM_50.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1056280.0</td>\n",
       "      <td>-3.06744</td>\n",
       "      <td>j</td>\n",
       "      <td>676000.0</td>\n",
       "      <td>640429.0</td>\n",
       "      <td>0.330450</td>\n",
       "      <td>0.704554</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>354</td>\n",
       "      <td>monojet_Zp2000.0_DM_50.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>631781.0</td>\n",
       "      <td>1.64181</td>\n",
       "      <td>j</td>\n",
       "      <td>936707.0</td>\n",
       "      <td>616229.0</td>\n",
       "      <td>0.973383</td>\n",
       "      <td>-1.565920</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354</td>\n",
       "      <td>monojet_Zp2000.0_DM_50.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>457316.0</td>\n",
       "      <td>-1.87536</td>\n",
       "      <td>j</td>\n",
       "      <td>640313.0</td>\n",
       "      <td>589524.0</td>\n",
       "      <td>0.390749</td>\n",
       "      <td>1.237340</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event ID                process ID  event weight        MET   METphi obj1  \\\n",
       "0       354  monojet_Zp2000.0_DM_50.0      0.000024   832841.0 -1.22431    b   \n",
       "1       354  monojet_Zp2000.0_DM_50.0      0.000024   732115.0  1.17245    j   \n",
       "2       354  monojet_Zp2000.0_DM_50.0      0.000024  1056280.0 -3.06744    j   \n",
       "3       354  monojet_Zp2000.0_DM_50.0      0.000024   631781.0  1.64181    j   \n",
       "4       354  monojet_Zp2000.0_DM_50.0      0.000024   457316.0 -1.87536    j   \n",
       "\n",
       "          E1       pt1      eta1      phi1  ... obj11  E11  pt11  eta11  \\\n",
       "0   947383.0  824498.0 -0.523103  1.644210  ...  None  NaN   NaN    NaN   \n",
       "1  1069460.0  751597.0  0.858186 -1.842170  ...  None  NaN   NaN    NaN   \n",
       "2   676000.0  640429.0  0.330450  0.704554  ...  None  NaN   NaN    NaN   \n",
       "3   936707.0  616229.0  0.973383 -1.565920  ...  None  NaN   NaN    NaN   \n",
       "4   640313.0  589524.0  0.390749  1.237340  ...  None  NaN   NaN    NaN   \n",
       "\n",
       "   phi11 obj12  E12  pt12  eta12  phi12  \n",
       "0    NaN  None  NaN   NaN    NaN    NaN  \n",
       "1    NaN  None  NaN   NaN    NaN    NaN  \n",
       "2    NaN  None  NaN   NaN    NaN    NaN  \n",
       "3    NaN  None  NaN   NaN    NaN    NaN  \n",
       "4    NaN  None  NaN   NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('sentinel', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries in the training data: 22661\n",
      "          E        pt       eta      phi\n",
      "0  258722.0  243675.0  0.328962  2.25014\n",
      "1  520092.0  108590.0 -2.247300 -1.85679\n",
      "2  383024.0   88405.6  2.145160 -1.95635\n",
      "3   39507.6   35365.1  0.470460 -1.16445\n",
      "4  225430.0   26878.2 -2.816080 -2.25938\n"
     ]
    }
   ],
   "source": [
    "# filter the dataframe to keep only jet particles and their values of E, pt, eta and phi\n",
    "filtered_particles = list()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    for i in range(1, n_obj + 1): #iterate over different objects in an event.\n",
    "        if(row[f'obj{i}'] == 'j'):\n",
    "            e = row[f'E{i}']\n",
    "            pt = row[f'pt{i}']\n",
    "            eta = row[f'eta{i}']\n",
    "            phi = row[f'phi{i}']\n",
    "            \n",
    "            filtered_particles.append([e, pt, eta, phi])\n",
    "            \n",
    "data = pd.DataFrame(filtered_particles, columns=['E', 'pt', 'eta', 'phi'])\n",
    "print(f'The number of entries in the training data: {len(data)}')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample:\n",
      "              E        pt       eta       phi\n",
      "20878  439663.0   23641.3 -3.615320  1.175170\n",
      "20814  407765.0   58975.5  2.620520  0.665193\n",
      "3263   116917.0   48872.8  1.514560 -0.201870\n",
      "15712  559754.0  393083.0 -0.886642 -2.068420\n",
      "19068  557362.0   33117.5  3.515280  0.009702\n",
      "\n",
      "\n",
      "Testing sample:\n",
      "               E        pt       eta       phi\n",
      "17352  1015390.0  108284.0 -2.928150 -0.649529\n",
      "19519   510893.0   33371.4 -3.420440 -2.661620\n",
      "8257    143777.0   55284.9 -1.608830 -2.354660\n",
      "19272   360976.0   60713.7  2.468350  1.822350\n",
      "276     700033.0  683158.0 -0.132609 -2.288410\n",
      "\n",
      "\n",
      "The number of entries in the training data: 15862\n",
      "The number of entries in the validation data: 6799\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into train and test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "print('Training sample:')\n",
    "print(train.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Testing sample:')\n",
    "print(test.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'The number of entries in the training data: {len(train)}')\n",
    "print(f'The number of entries in the validation data: {len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_log(train_x, test_x, f_name):\n",
    "    train_x[f_name] = train_x[f_name].apply(lambda x : np.log(1 + x))\n",
    "    test_x[f_name] = test_x[f_name].apply(lambda x : np.log(1 + x))\n",
    "    \n",
    "    return train_x, test_x\n",
    "    \n",
    "def apply_scaler(train_x, test_x, f_name, scaler):\n",
    "    scaler.fit(train_x[f_name].to_numpy().reshape(-1, 1))\n",
    "    train_x[f_name] = scaler.transform(train_x[f_name].to_numpy().reshape(-1, 1))\n",
    "    test_x[f_name] = scaler.transform(test_x[f_name].to_numpy().reshape(-1, 1))\n",
    "    \n",
    "    return train_x, test_x, scaler\n",
    "    \n",
    "def custom_scaler(train, test):\n",
    "    #Since \\eta follows a normal distribution, we can use standardScaler to scale it.\n",
    "    #For E and pt we can use log(1 + x)\n",
    "    # for \\phi, we can use MinMaxScaling\n",
    "    \n",
    "    train_x = train.copy(deep=True)\n",
    "    test_x = test.copy(deep=True)\n",
    "    \n",
    "    standard_scaler_eta = StandardScaler()\n",
    "    min_max_scaler_e = MinMaxScaler()\n",
    "    min_max_scaler_pt = MinMaxScaler()\n",
    "    min_max_scaler_phi = MinMaxScaler()\n",
    "    \n",
    "    \n",
    "    train_x, test_x = apply_log(train_x, test_x, 'E')\n",
    "    train_x, test_x, min_max_scaler_e = apply_scaler(train_x, test_x, 'E', min_max_scaler_e)\n",
    "    \n",
    "    train_x, test_x = apply_log(train_x, test_x, 'pt')\n",
    "    train_x, test_x, min_max_scaler_pt = apply_scaler(train_x, test_x, 'pt', min_max_scaler_pt)\n",
    "    \n",
    "    train_x, test_x, standard_scaler_eta = apply_scaler(train_x, test_x, 'eta', standard_scaler_eta)\n",
    "    \n",
    "    train_x, test_x, min_max_scaler_phi = apply_scaler(train_x, test_x, 'phi', min_max_scaler_phi)\n",
    "    \n",
    "    return train_x, test_x, min_max_scaler_e, min_max_scaler_pt, standard_scaler_eta, min_max_scaler_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_inverse_scaler(data_x, f_name, scaler):\n",
    "    data_x[f_name] = scaler.inverse_transform(data_x[f_name].to_numpy().reshape(-1, 1))\n",
    "    \n",
    "    return data_x \n",
    "\n",
    "def apply_exp(data_x, f_name):\n",
    "    data_x[f_name] = data_x[f_name].apply(lambda x : np.exp(1 + x))\n",
    "    \n",
    "    return data_x\n",
    "\n",
    "def denormalise_data(data, min_max_scaler_e, min_max_scaler_pt, standard_scaler_eta, min_max_scaler_phi):\n",
    "    \n",
    "    data_x = data.copy(deep=True)\n",
    "    data_x = apply_inverse_scaler(data_x, 'E', min_max_scaler_e)\n",
    "    data_x = apply_exp(data_x, 'E')\n",
    "    \n",
    "    data_x = apply_inverse_scaler(data_x, 'pt', min_max_scaler_pt)\n",
    "    data_x = apply_exp(data_x, 'pt')\n",
    "    \n",
    "    data_x = apply_inverse_scaler(data_x, 'eta', standard_scaler_eta)\n",
    "    \n",
    "    data_x = apply_inverse_scaler(data_x, 'phi', min_max_scaler_phi)\n",
    "    \n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_div = 5\n",
    "phi_div = 3\n",
    "\n",
    "m_add = 1\n",
    "m_div = 1.8\n",
    "\n",
    "pt_div = 1.2\n",
    "pt_sub = 1.3\n",
    "\n",
    "def prev_normalize(data):\n",
    "    data['eta'] = data['eta'] / eta_div\n",
    "    data['phi'] = data['phi'] / phi_div\n",
    "    data['E'] = np.log10(data['E'] + m_add) / m_div\n",
    "    data['pt'] = (np.log10(data['pt']) - pt_sub) / pt_div\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised Training sample:\n",
      "              E        pt       eta       phi\n",
      "20878  0.563189  0.013301 -2.427364  0.687074\n",
      "20814  0.548523  0.214889  1.740362  0.605904\n",
      "3263   0.305282  0.173452  1.001193  0.467897\n",
      "15712  0.610210  0.633211 -0.603651  0.170807\n",
      "19068  0.609376  0.087632  2.338375  0.501572\n",
      "\n",
      "\n",
      "Normalised Testing sample:\n",
      "              E        pt       eta       phi\n",
      "17352  0.726169  0.348890 -1.968093  0.396645\n",
      "19519  0.592426  0.089316 -2.297115  0.076390\n",
      "8257   0.345548  0.200638 -1.086325  0.125247\n",
      "19272  0.524792  0.221295  1.638659  0.790083\n",
      "276    0.653754  0.755100 -0.099692  0.135792\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 for proposed normalizing method, 4 for previous normalizing method\n",
    "scaling_method = 1\n",
    "\n",
    "if (scaling_method == 1):\n",
    "    train_x, test_x, min_max_scaler_e, min_max_scaler_pt, standard_scaler_eta, min_max_scaler_phi \\\n",
    "        = custom_scaler(train, test)\n",
    "\n",
    "elif (scaling_method == 4):\n",
    "    train_x = prev_normalize(train)\n",
    "    test_x = prev_normalize(test)\n",
    "\n",
    "print('Normalised Training sample:')\n",
    "print(train_x.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Normalised Testing sample:')\n",
    "print(test_x.head())\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_y = train_x  # y = x since we are building an autoencoder\n",
    "test_y = test_x\n",
    "\n",
    "from fastai import learner\n",
    "from fastai.data import core\n",
    "\n",
    "# Constructs a tensor object of the data and wraps them in a TensorDataset object.\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values, dtype=torch.float), torch.tensor(train_y.values, dtype=torch.float))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "\n",
    "# Converts the TensorDataset into a DataLoader object and combines into one DataLoaders object (a basic wrapper\n",
    "# around several DataLoader objects). \n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
    "dls = core.DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_3D_200_LeakyReLU(\n",
       "  (en1): Linear(in_features=4, out_features=200, bias=True)\n",
       "  (en2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (en3): Linear(in_features=200, out_features=20, bias=True)\n",
       "  (en4): Linear(in_features=20, out_features=3, bias=True)\n",
       "  (de1): Linear(in_features=3, out_features=20, bias=True)\n",
       "  (de2): Linear(in_features=20, out_features=200, bias=True)\n",
       "  (de3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (de4): Linear(in_features=200, out_features=4, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  class AE_3D_200_LeakyReLU(nn.Module):\n",
    "    def __init__(self, n_features=4):\n",
    "        super(AE_3D_200_LeakyReLU, self).__init__()\n",
    "        self.en1 = nn.Linear(n_features, 200)\n",
    "        self.en2 = nn.Linear(200, 200)\n",
    "        self.en3 = nn.Linear(200, 20)\n",
    "        self.en4 = nn.Linear(20, 3)\n",
    "        \n",
    "        self.de1 = nn.Linear(3, 20)\n",
    "        self.de2 = nn.Linear(20, 200)\n",
    "        self.de3 = nn.Linear(200, 200)\n",
    "        self.de4 = nn.Linear(200, n_features)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.en4(self.tanh(self.en3(self.tanh(self.en2(self.tanh(self.en1(x)))))))\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.de4(self.tanh(self.de3(self.tanh(self.de2(self.tanh(self.de1(self.tanh(x))))))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)\n",
    "\n",
    "    def describe(self):\n",
    "        return 'in-200-200-20-3-20-200-200-out'\n",
    "\n",
    "model = AE_3D_200_LeakyReLU()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import mse\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "wd = 1e-6\n",
    "\n",
    "recorder = learner.Recorder()\n",
    "learn = learner.Learner(dls, model=model, wd=wd, loss_func=loss_func, cbs=recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate with the minimum loss: 0.004786301031708717\n",
      "Learning rate with the steepest gradient: 0.0030199517495930195\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.callback import schedule\n",
    "\n",
    "lr_min, lr_steep = learn.lr_find()\n",
    "\n",
    "print('Learning rate with the minimum loss:', lr_min)\n",
    "print('Learning rate with the steepest gradient:', lr_steep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.13608141243457794, 0.06950002163648605, '00:00']\n",
      "[0, 0.13608141243457794, 0.06950002163648605, '00:00']\n",
      "[1, 0.06602589786052704, 0.029712071642279625, '00:00']\n",
      "[1, 0.06602589786052704, 0.029712071642279625, '00:00']\n",
      "[2, 0.03400570526719093, 0.01875658705830574, '00:00']\n",
      "[2, 0.03400570526719093, 0.01875658705830574, '00:00']\n",
      "[3, 0.015065553598105907, 0.0043107750825583935, '00:00']\n",
      "[3, 0.015065553598105907, 0.0043107750825583935, '00:00']\n",
      "[4, 0.00669979490339756, 0.0029938772786408663, '00:00']\n",
      "[4, 0.00669979490339756, 0.0029938772786408663, '00:00']\n",
      "[5, 0.0035504805855453014, 0.0018890954088419676, '00:00']\n",
      "[5, 0.0035504805855453014, 0.0018890954088419676, '00:00']\n",
      "[6, 0.0017009227303788066, 0.0005838855286128819, '00:00']\n",
      "[6, 0.0017009227303788066, 0.0005838855286128819, '00:00']\n",
      "[7, 0.0007032444118522108, 0.00017976894741877913, '00:00']\n",
      "[7, 0.0007032444118522108, 0.00017976894741877913, '00:00']\n",
      "[8, 0.0007069850689731538, 0.000246406183578074, '00:00']\n",
      "[8, 0.0007069850689731538, 0.000246406183578074, '00:00']\n",
      "[9, 0.0004259270499460399, 0.00017161021241918206, '00:00']\n",
      "[9, 0.0004259270499460399, 0.00017161021241918206, '00:00']\n",
      "[10, 0.0007331018568947911, 0.0001586850848980248, '00:00']\n",
      "[10, 0.0007331018568947911, 0.0001586850848980248, '00:00']\n",
      "[11, 0.0007868390530347824, 0.00043294703937135637, '00:00']\n",
      "[11, 0.0007868390530347824, 0.00043294703937135637, '00:00']\n",
      "[12, 0.0014950954355299473, 0.00048264197539538145, '00:00']\n",
      "[12, 0.0014950954355299473, 0.00048264197539538145, '00:00']\n",
      "[13, 0.0010168756125494838, 0.0002458433446008712, '00:00']\n",
      "[13, 0.0010168756125494838, 0.0002458433446008712, '00:00']\n",
      "[14, 0.0008901942055672407, 0.0010169538436457515, '00:00']\n",
      "[14, 0.0008901942055672407, 0.0010169538436457515, '00:00']\n",
      "[15, 0.0015190655831247568, 0.0008611080120317638, '00:00']\n",
      "[15, 0.0015190655831247568, 0.0008611080120317638, '00:00']\n",
      "[16, 0.002569411415606737, 0.0017267564544454217, '00:00']\n",
      "[16, 0.002569411415606737, 0.0017267564544454217, '00:00']\n",
      "[17, 0.0014718127204105258, 0.00028807195485569537, '00:00']\n",
      "[17, 0.0014718127204105258, 0.00028807195485569537, '00:00']\n",
      "[18, 0.0013757924316450953, 0.01318155974149704, '00:00']\n",
      "[18, 0.0013757924316450953, 0.01318155974149704, '00:00']\n",
      "[19, 0.0015899942955002189, 0.0009485108312219381, '00:00']\n",
      "[19, 0.0015899942955002189, 0.0009485108312219381, '00:00']\n",
      "[20, 0.0016347963828593493, 0.0005123308510519564, '00:00']\n",
      "[20, 0.0016347963828593493, 0.0005123308510519564, '00:00']\n",
      "[21, 0.0013506509130820632, 0.0027638401370495558, '00:00']\n",
      "[21, 0.0013506509130820632, 0.0027638401370495558, '00:00']\n",
      "[22, 0.0014805750688537955, 0.0011290621478110552, '00:00']\n",
      "[22, 0.0014805750688537955, 0.0011290621478110552, '00:00']\n",
      "[23, 0.0015607232926413417, 0.0030494797974824905, '00:00']\n",
      "[23, 0.0015607232926413417, 0.0030494797974824905, '00:00']\n",
      "[24, 0.0014918281231075525, 0.0003089557576458901, '00:00']\n",
      "[24, 0.0014918281231075525, 0.0003089557576458901, '00:00']\n",
      "[25, 0.0016685640439391136, 0.0018684100359678268, '00:00']\n",
      "[25, 0.0016685640439391136, 0.0018684100359678268, '00:00']\n",
      "[26, 0.001257760333828628, 0.0013221533736214042, '00:00']\n",
      "[26, 0.001257760333828628, 0.0013221533736214042, '00:00']\n",
      "[27, 0.0022859147284179926, 0.0020840323995798826, '00:00']\n",
      "[27, 0.0022859147284179926, 0.0020840323995798826, '00:00']\n",
      "[28, 0.0013090787688270211, 0.000528809439856559, '00:00']\n",
      "[28, 0.0013090787688270211, 0.000528809439856559, '00:00']\n",
      "[29, 0.0012553032720461488, 0.0018085825722664595, '00:00']\n",
      "[29, 0.0012553032720461488, 0.0018085825722664595, '00:00']\n",
      "[30, 0.00106100516859442, 0.0009035400580614805, '00:00']\n",
      "[30, 0.00106100516859442, 0.0009035400580614805, '00:00']\n",
      "[31, 0.0009134590509347618, 0.000852815865073353, '00:00']\n",
      "[31, 0.0009134590509347618, 0.000852815865073353, '00:00']\n",
      "[32, 0.0011633210815489292, 0.001035310560837388, '00:00']\n",
      "[32, 0.0011633210815489292, 0.001035310560837388, '00:00']\n",
      "[33, 0.0008443052065558732, 0.0002990046050399542, '00:00']\n",
      "[33, 0.0008443052065558732, 0.0002990046050399542, '00:00']\n",
      "[34, 0.0014737652381882071, 0.0007929580169729888, '00:00']\n",
      "[34, 0.0014737652381882071, 0.0007929580169729888, '00:00']\n",
      "[35, 0.000661075406242162, 0.00027907147887162864, '00:00']\n",
      "[35, 0.000661075406242162, 0.00027907147887162864, '00:00']\n",
      "[36, 0.000906048808246851, 0.0010773144895210862, '00:00']\n",
      "[36, 0.000906048808246851, 0.0010773144895210862, '00:00']\n",
      "[37, 0.0009081381722353399, 0.0019236118532717228, '00:00']\n",
      "[37, 0.0009081381722353399, 0.0019236118532717228, '00:00']\n",
      "[38, 0.0006930592353455722, 0.00031642676913179457, '00:00']\n",
      "[38, 0.0006930592353455722, 0.00031642676913179457, '00:00']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter() # Starts timer\n",
    "learn.fit_one_cycle(100, lr_min)\n",
    "end = time.perf_counter() # Ends timer\n",
    "delta_t = end - start\n",
    "print('Training took', delta_t, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
